{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": "# Federated Learning CIFAR10 Swarm Deployment\n\nThis notebook demonstrates how to deploy a federated learning swarm for CIFAR10 image classification on the Manta platform.\n\n## What You'll Learn\n\n1. **Setting up the connection** to the Manta platform\n2. **Defining modules and federated learning swarm** with workers, aggregator, and scheduler\n3. **Deploying the swarm** to a cluster\n4. **Monitoring results** from training and evaluation\n\n## Prerequisites\n\nBefore running this notebook, ensure you have completed the following steps:\n\n### 1. Create an Account\n- Visit [dashboard.manta-tech.io](https://dashboard.manta-tech.io) and create an account\n- Create a new cluster and start it\n\n### 2. Install Manta SDK\nInstall the Manta SDK in your Python environment:\n```bash\npip install manta-sdk\n```\n\n### 3. Partition the Dataset\nRun the data preparation script to partition the CIFAR10 dataset for multiple nodes:\n```bash\npython prepare_data.py -n <number_of_nodes>\n```\nThis will create partitioned CIFAR10 data in `temp/partitioned/node_0/`, `temp/partitioned/node_1/`, etc.\n\n### 4. Install and Configure Manta Nodes\nInstall manta-node on each device that will participate in training:\n```bash\npip install manta-node\n```\n\nDownload node configuration from the Manta dashboard (see \"Configure New Node\" button on your cluster page) and save it in `~/.manta/nodes/<node_name>.toml`\n\n**Important**: Configure each node's dataset path to point to its partition:\n- Node 0: dataset path = `/path/to/temp/partitioned/node_0/cifar10.npz`\n- Node 1: dataset path = `/path/to/temp/partitioned/node_1/cifar10.npz`\n- etc.\n\n### 5. Start Manta Nodes\nLaunch each Manta node with its configuration:\n```bash\nmanta node start <node_name>\n```\n\nVerify nodes are connected by checking your cluster dashboard.\n\n### 6. Docker Image\nEnsure the Docker image `manta_light:pytorch` is available on your nodes, or modify the `image` variable in this notebook."
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": "## Step 1: Import Libraries and Configure Authentication\n\nFirst, import the necessary libraries and configure your authentication credentials.\n\n**Replace the credentials below with your actual account credentials from dashboard.manta-tech.io**"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from manta.apis.async_user_api import AsyncUserAPI\n",
    "from pathlib import Path\n",
    "\n",
    "from manta import Module, Swarm, Task\n",
    "from modules.worker import CNN\n",
    "\n",
    "# Replace with your credentials from dashboard.manta-tech.io\n",
    "USERNAME = \"your-email@example.com\"\n",
    "PASSWORD = \"your-password\"\n",
    "\n",
    "api = await AsyncUserAPI.sign_in(\n",
    "    USERNAME,\n",
    "    PASSWORD,\n",
    "    host=\"api.manta-tech.io\",\n",
    "    port=443,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 2: Connect to Manta Platform and Find Active Cluster\n",
    "\n",
    "This section establishes a connection to the Manta platform and locates an active cluster for deployment:\n",
    "\n",
    "1. **Initialize UserAPI**: Creates a connection to the Manta manager service\n",
    "2. **Check availability**: Verifies the connection is working\n",
    "3. **Find active cluster**: Searches for a running cluster to deploy the swarm\n",
    "\n",
    "The cluster API will be used for all subsequent operations including swarm deployment, monitoring, and log streaming.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "availability_message = await api.is_available()\n",
    "print(f\"UserAPI availability: {availability_message}\")\n",
    "\n",
    "# Find an active (RUNNING) cluster\n",
    "print(\"\\nSearching for active cluster...\")\n",
    "async for cluster in api.stream_clusters():\n",
    "    # Status 1 = RUNNING, 0 = CREATED, 2 = INACTIVE\n",
    "    if cluster[\"status\"] == 1:\n",
    "        print(\"===================Active Cluster Found===================\")\n",
    "        print(f\"Cluster ID: {cluster['cluster_id']}\")\n",
    "        print(f\"Cluster Name: {cluster['name']}\")\n",
    "        print(\"Status: RUNNING\")\n",
    "        active_cluster_id = cluster[\"cluster_id\"]\n",
    "        break\n",
    "else:\n",
    "    print(\"No running cluster found. Please start a cluster from the dashboard.\")\n",
    "    raise RuntimeError(\"No active cluster available\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 3: Define Modules\n",
    "\n",
    "First, let's define all the modules that will be used in our federated learning swarm. This separation makes it easier to understand and modify each component independently.\n",
    "\n",
    "### Module Definitions for CIFAR10\n",
    "\n",
    "Each module represents a specific task in the federated learning workflow:\n",
    "- **Aggregator Module**: Combines model weights from workers using federated averaging\n",
    "- **Worker Module**: Trains CNN models on distributed CIFAR10 data\n",
    "- **Scheduler Module**: Coordinates training rounds and checks convergence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the modules that will be used in the swarm\n",
    "root_path = Path().resolve()\n",
    "image = \"manta_light:pytorch\"\n",
    "gpu = False  # Set to True to use GPU for better performance with CNN\n",
    "\n",
    "# Aggregator Module\n",
    "aggregator_module = Module(\n",
    "    root_path / \"modules\" / \"aggregator.py\",\n",
    "    image,\n",
    "    datasets=[],\n",
    ")\n",
    "\n",
    "# Worker Module (CNN training on CIFAR10)\n",
    "worker_module = Module(\n",
    "    root_path / \"modules\" / \"worker.py\",\n",
    "    image,\n",
    "    datasets=[\"cifar10\"],\n",
    ")\n",
    "\n",
    "# Scheduler Module\n",
    "scheduler_module = Module(\n",
    "    root_path / \"modules\" / \"scheduler.py\",\n",
    "    image,\n",
    "    datasets=[],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 4: Define the Federated Learning Swarm\n",
    "\n",
    "Now we'll create the FLSwarm class that uses the modules defined above. This approach separates the module definitions from the swarm logic, making the code more modular and easier to understand.\n",
    "\n",
    "### CIFAR10 FL Architecture\n",
    "\n",
    "The swarm implements a simpler workflow compared to MNIST, focusing on the core FL loop:\n",
    "```\n",
    "Worker (CNN Training) → Aggregator (FedAvg) → Scheduler (Convergence Check) → Loop/End\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FLSwarm(Swarm):\n",
    "    def __init__(\n",
    "        self,\n",
    "        aggregator_module: Module,\n",
    "        worker_module: Module,\n",
    "        scheduler_module: Module,\n",
    "        gpu: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # Create tasks from the provided modules\n",
    "        self.aggregator = Task(\n",
    "            aggregator_module,\n",
    "            method=\"any\",\n",
    "            fixed=False,\n",
    "            maximum=1,\n",
    "            gpu=False,\n",
    "        )\n",
    "\n",
    "        self.worker = Task(\n",
    "            worker_module,\n",
    "            method=\"all\",\n",
    "            fixed=False,\n",
    "            maximum=-1,\n",
    "            gpu=gpu,\n",
    "        )\n",
    "\n",
    "        self.scheduler = Task(\n",
    "            scheduler_module,\n",
    "            method=\"any\",\n",
    "            fixed=False,\n",
    "            maximum=1,\n",
    "            gpu=False,\n",
    "        )\n",
    "\n",
    "        # Set hyperparameters optimized for CIFAR10 CNN training\n",
    "        self.set_global(\n",
    "            \"hyperparameters\",\n",
    "            {\n",
    "                \"epochs\": 1,\n",
    "                \"batch_size\": 64,\n",
    "                \"loss\": \"CrossEntropyLoss\",\n",
    "                \"loss_params\": {},\n",
    "                \"optimizer\": \"SGD\",\n",
    "                \"optimizer_params\": {\n",
    "                    \"lr\": 0.001,\n",
    "                    \"momentum\": 0.9,\n",
    "                    \"weight_decay\": 5e-4,\n",
    "                },\n",
    "                \"val_acc_threshold\": 0.80,  # Lower threshold for CIFAR10\n",
    "            },\n",
    "        )\n",
    "        # Set global model parameters (CNN weights)\n",
    "        self.set_global(\"global_model_params\", CNN().get_weights())\n",
    "\n",
    "    def execute(self):\n",
    "        \"\"\"\n",
    "        Generation of the task graph\n",
    "\n",
    "        +--------+     +------------+     +-----------+ if has_converged\n",
    "        | Worker | --> | Aggregator | --> | Scheduler | ----------------> END PROGRAM\n",
    "        +--------+     +------------+     +-----------+\n",
    "            |                                   | else\n",
    "            +--<<<----------<<<----------<<<----+\n",
    "        \"\"\"\n",
    "        m = self.worker()\n",
    "        m = self.aggregator(m)\n",
    "        return self.scheduler(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the swarm instance using the pre-defined modules\n",
    "swarm = FLSwarm(\n",
    "    aggregator_module=aggregator_module,\n",
    "    worker_module=worker_module,\n",
    "    scheduler_module=scheduler_module,\n",
    "    gpu=gpu,\n",
    ")\n",
    "\n",
    "print(\"CIFAR10 Federated Learning Swarm created successfully!\")\n",
    "print(f\"Using GPU: {gpu}\")\n",
    "print(f\"Image: {image}\")\n",
    "print(\"Ready for deployment to cluster!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 5: Deploy the Swarm\n",
    "\n",
    "Now we can deploy the swarm to the active cluster and monitor its execution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy the swarm to the cluster\n",
    "swarm_overview = await cluster_api.send_swarm(swarm)\n",
    "print(\"Swarm deployed successfully!\")\n",
    "print(f\"Swarm ID: {swarm_overview['swarm_id']}\")\n",
    "print(f\"Status: {swarm_overview['status']}\")\n",
    "print(f\"Created at: {swarm_overview['datetime']}\")\n",
    "\n",
    "# Start the swarm execution\n",
    "start_response = await cluster_api.start_swarm(swarm_overview[\"swarm_id\"])\n",
    "print(\"\\nSwarm execution started!\")\n",
    "print(f\"Start response: {start_response}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}